Случайный лес - ансамбль, совокупность нескольких моделей машинного обучения.

Здесь, мы будем пользоваться преимуществами деревьев решений, в тоже время устраняя возникающую дисперсию.

Начальная загрузка (Bootstraping):
    Это случайная выборка точек данных, в которой мы случайным образом выбираем точки данных с заменой из нашего исходного набора данных, чтобы создать набор данных того же размера.
    
    Случайный выбор с заменой означает, что мы можем выбрать одну и ту же точку данных несколько раз.
    Это означает, что в загрузочном образце некоторые точки данных из исходного набора данных будут отображаться несколько раз, а некоторые не будут отображаться вообще.

    Пример (четыре точки данных A, B, C, D):
        Допустим 3 образца

        А, А, B, C
        В, В, В, D
        А, А, С, С

    Поскольку всё, что у нас есть, - это наш обучающий набор, мы используем его для создания дополнительных наборов данных.

Пакетирование (Bagging):
    Пакетирование - агрегирование начальной загрузки - метод уменьшения дисперсии в отдельной модели путём создания ансамбля из нескольких моделей, построенных на загрузочных образцах.

    Чтобы собрать деревья решений, мы создаем несколько (скажем, 10) загрузочных повторных примеров нашего обучающего набора данных. Таким образом, если у нас есть 100 точек данных в нашем обучающем наборе, каждая из повторных выборок будет иметь 100 точек данных, случайно выбранных из нашего обучающего набора. Напомним, что мы выбираем случайным образом с заменой, что означает, что некоторые точки данных будут появляться несколько раз, а некоторые - вообще ни разу.

    Мы создаем дерево решений с каждой из этих 10 повторных выборок.

    Чтобы сделать прогноз, мы делаем прогноз с каждым из 10 деревьев решений, а затем каждое дерево решений получает право голоса. Прогноз, набравший наибольшее количество голосов, является окончательным прогнозом.

    Когда мы загружаем обучающий набор, мы пытаемся устранить различия в дереве решений. Среднее значение нескольких деревьев, имеющих разные обучающие наборы, создаст модель, которая более точно отражает суть данных.


Декорреляция (Decorrelate):
    Добавление некоторых ограничений, чтобы увеличить вариативность.

    На каждом узле мы случайным образом выбираем подмножество объектов для рассмотрения.

    Случайный выбор функций происходит на каждом узле.

    Традиционно кол-во свойств, которое стоит учитывать на каждом разбиении равно квадратному корню из общего кол-ва свойств. Если у нас всего 9 свойств, то на каждом разбиении мы будем рассмтривать 3 случайно выбранных свойств из общего списка.

    Если мы собирём эти деревья решений воедино, получим искомуый случайный лес.


    Каждое дерево решений внутри случайного леса вероятнее всего хуже простого дерева решений, но, когда мы их усредняем, получаем очень точную модель.